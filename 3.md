# Оценка максимального правдоподобия, как она связана с регрессией и классификацией

#### Оценка максимального правдоподобия.

> Функция правдоподобия: $L_\theta(X)=p_\theta(X_1)p_\theta(X_2)\dots p_\theta(X_n)$.

> MLE (Maximum Likelihood Estimation, оценка максимального правдоподобия) - это метод оценивания неизвестного параметра распределения путем максимизации функции правдоподобия.  
$\theta_{MLE} = argmax_{\theta \in \Theta}L_\theta(X)$

Поясню, пусть есть выборка $X$, мы (как обычно) хотим узнать какое у нее распределение. Мы предполагаем, что оно из какого-то параметрического класса распределений: $P_\theta$, где $\theta \in \Theta$. Тогда задача сводится к подбору этого самого параметра $\theta$.   
Рассмотрим какое-то $\theta$ и соответствующее ему распределение $P_\theta$. Если предположить, что выборка пришла из него, то можно найти плотность каждого элемента выборки: $p_\theta\left(X_i\right)$. Тогда произведение всех таких плотностей называется **функцией правдоподобия**. Т.е. $L_{\theta}(X)$ - это вероятность получить выборку $X$ в распределении $P_\theta$.  
Почему хочется ее максимизировать? Логично, что если $P_\theta$ - истинное распределение и элементы $X$ пришли из него, то в $X$ окажутся значения, вероятность которых велика в $P_\theta$. Соответственно их плотности тоже будут велики. 

#### Связь с регрессией.

> хз почему тут речь про регрессию и классификацию, вроде бы логичнее говорить про линейную регрессию и логистическую регрессию.

![Alt text](/img/3.0.png)
![Alt text](/img/3.1.png)
![Alt text](/img/3.2.png)
> Тут стоит добавить, что оценка, полученная с помощью $MLE$ будет оптимальной (т.е. очень крутой в матстатах). Почему так? По теореме Гаусса-Маркова: ![Alt text](/img/3.3.png)

#### Связь с классификацией.
![Alt text](/img/3.4.png)
![Alt text](/img/3.5.png)
![Alt text](/img/3.6.png)

# Источники:
1. [wikipedia теорема Гаусса-Маркова](https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BE%D1%80%D0%B5%D0%BC%D0%B0_%D0%93%D0%B0%D1%83%D1%81%D1%81%D0%B0_%E2%80%94_%D0%9C%D0%B0%D1%80%D0%BA%D0%BE%D0%B2%D0%B0)  
2. [хендбук 4.1](https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml)